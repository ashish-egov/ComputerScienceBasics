# ComputerScienceBasics

## Early Computing

-   Mechanical devices such as the abacus and  Jacquard loom  were the first computers.
-   Charles Babbage designed the  Analytical Engine, the first programmable machine.
-   Ada Lovelace is credited with creating the first  computer program  for the Analytical Engine.
-   Alan Turing described the  Universal Turing Machine, capable of performing any computation.
-   The first electronic computer,  ENIAC, was built in the 1940s to calculate  ballistic trajectories.

## Electronic Computing

-   The development of the transistor paved the way for the miniaturization of electronic components and the creation of the modern computer.
-   The first commercially successful computer was the  UNIVAC, introduced in the 1950s.
-   IBM dominated the computer industry in the 1960s with its System/360 mainframe computer.
-   The invention of the microprocessor in the 1970s allowed for the creation of personal computers.

## Boolean Logic & Logic Gates

-   Boolean logic  is a system of logic based on two values: true and false.
-   Logic gates  are electronic circuits that implement Boolean logic.
-   The three basic logic gates are AND, OR, and NOT.
-   Other logic gates include NAND, NOR, XOR, and  XNOR.
-   Logic gates can be combined to create more complex circuits, such as adders  and  flip-flops.

## Representing Numbers and Letters with Binary

-   Binary is a  number system  based on two values: 0 and 1.
-   Computers use  binary  to represent numbers and letters.
-   ASCII is a standard  encoding scheme  that assigns a unique  binary code  to each character.
-   Unicode is a more comprehensive encoding scheme that supports a wider range of characters and languages.

## How Computers Calculate - the ALU

-   The Arithmetic Logic Unit (ALU) is a component of the computer that performs arithmetic and  logical operations.
-   The ALU operates on  binary numbers  using logic gates and circuits.
-   The ALU can perform addition, subtraction, multiplication, division, and  bitwise operations.
-   The ALU is controlled by the computer's central processing unit (CPU).

## Registers and RAM

-   Registers are small, fast storage locations within the CPU that hold data temporarily.
-   RAM  (Random Access Memory) is the primary memory of a computer, which can be read from and written to.
-   RAM is volatile, meaning that its contents are lost when the computer is turned off.
-   Accessing data in RAM is slower than accessing data in registers, but much faster than accessing data from secondary storage devices like hard drives.

## The Central Processing Unit (CPU)

-   The CPU is the "brain" of the computer, responsible for executing instructions.
-   The CPU consists of an  arithmetic logic unit  (ALU), control unit (CU), and registers.
-   The CU fetches instructions from memory and decodes them into operations the ALU can perform, then sends the results back to memory or registers.
-   The clock speed of a CPU measures how many instructions it can execute per second.

## Instructions & Programs

-   Programs are a sequence of instructions that tell the computer what to do.
-   Instructions are encoded in binary and stored in memory.
-   The fetch-decode-execute cycle is the process by which the CPU retrieves instructions from memory, decodes them, and executes them.
-   High-level programming languages allow programmers to write code in a more human-readable form, which is then translated into  machine code  by a compiler or interpreter.

## Advanced CPU  Designs

-   Pipelining  is a technique used by modern CPUs to execute multiple instructions simultaneously, by overlapping the fetch-decode-execute cycle.
-   Superscalar processors can execute  multiple instructions  in parallel by having multiple execution units.
-   Branch prediction  is a technique used by modern CPUs to predict which branch of code will be executed next, in order to minimize the number of cycles wasted on incorrect predictions.
-   Cache is a small, fast memory located on the  CPU chip  that stores frequently accessed data to reduce the amount of time spent accessing main memory.

## Early Programming

-   Early programming languages were often low-level and difficult to use, requiring programmers to write instructions in binary or  assembly language.
-   Grace Hopper invented the first compiler, which allowed programmers to write code in a higher-level language that was then automatically translated into machine code.
-   FORTRAN was the first high-level programming language, designed for scientific and engineering applications.
-   COBOL was designed for business applications, while  BASIC  was designed for beginners.

## First Programming Languages

-   The  first programming languages  were developed in the 1950s and 1960s.
-   Some of the earliest  programming languages  were  Fortran,  Lisp, and  COBOL.
-   Fortran was designed for scientific and engineering applications, Lisp was designed for  artificial intelligence  research, and COBOL was designed for business applications.
-   These languages were used to write programs that could be executed on computers, which were becoming more widely available at the time.

## Programming Basics: Statements & Functions

-   Programming is the process of writing code to tell a computer what to do.
-   Programs are made up of statements, which are instructions that tell the computer what to do.
-   Functions are reusable pieces of code that perform specific tasks.
-   Variables are used to store data that can be used by the program.
-   Conditional statements  allow the program to make decisions based on certain conditions.
-   Loops allow the program to repeat certain actions until a condition is met.

## Intro to Algorithms

-   An algorithm is a set of instructions for solving a problem or performing a task.
-   Algorithms are used in many areas, including computer science, mathematics, and engineering.
-   There are many different algorithms for solving the same problem, and some are more efficient than others.
-   The efficiency of an algorithm can be measured in terms of its runtime and  memory usage.
-   Big O notation is used to describe the runtime of an algorithm.

## Data Structures

-   Data structures are ways of organizing and storing data in a computer program.
-   Some common  data structures  include arrays,  linked lists, stacks, and queues.
-   Each  data structure  has its own advantages and disadvantages, depending on the specific needs of the program.
-   Algorithms often use data structures to efficiently process large amounts of data.

## Alan Turing

-   Alan Turing was a British mathematician and computer scientist who made important contributions to the development of computing and cryptography.
-   During World War II, Turing worked on breaking  German codes  using a machine called the Bombe.
-   After the war, Turing continued to work on computing and artificial intelligence research.
-   Turing is widely regarded as one of the pioneers of modern computing, and his work laid the foundation for many of the technologies we use today.


## 16. Software Engineering

### Overview

-   Software engineering  is the process of designing, creating, testing, and maintaining software applications using engineering principles.
-   It involves using various tools, techniques, and methodologies to ensure that software is reliable, efficient, and easy to use.

### Importance of Software Engineering

-   Software is ubiquitous in today's world and is used in a wide range of applications, from  mobile apps  to  complex enterprise systems.
-   Good software engineering practices can help ensure that software is high quality, secure, and meets user needs.

### Software Development Life Cycle (SDLC)

-   The software development life cycle (SDLC) is a framework for software engineering that includes several stages, such as requirements gathering, design, coding, testing, and maintenance.
-   Each stage involves different activities and processes that help ensure that software is developed to the best possible standards.

### Agile Development

-   Agile development is a popular approach to software engineering that emphasizes flexibility, collaboration, and  iterative development.
-   Agile development  involves breaking software development into small, manageable chunks and working closely with customers and stakeholders to ensure that the software meets their needs.

### Software Testing

-   Software testing is an important part of software engineering that involves verifying that software functions correctly and meets user requirements.
-   There are several types of testing, including  unit testing,  integration testing, and  acceptance testing.

### Other Important Aspects of Software Engineering

-   Software documentation: creating documentation that describes how the software works and how it should be used.
-   Version control: using a  version control system  to manage changes to the software over time.
-   Continuous integration  and deployment: automating the process of building, testing, and deploying software changes.

## 17. Integrated Circuits & Mooreâ€™s Law

### Overview

-   An integrated circuit (IC) is a small electronic device that contains multiple components, such as transistors, resistors, and capacitors, all on a single piece of semiconductor material.
-   ICs are used in a wide range of electronic devices, from computers to smartphones to medical equipment.

### Moore's Law

-   Moore's Law is an observation made by  Gordon Moore, co-founder of Intel, in 1965, that the number of transistors on a microchip doubles every 18-24 months.
-   This observation has held true for many decades and has been a driving force behind the development of faster, more powerful, and more energy-efficient electronic devices.

### Miniaturization of Transistors

-   The miniaturization of transistors and other components on an IC has been made possible by advances in semiconductor manufacturing technology, such as photolithography, which allows for the precise etching of features on a semiconductor material.
-   The continued miniaturization of components on an IC has led to the development of smaller, more powerful electronic devices that consume less power and generate less heat.

### Limits of Miniaturization

-   However, there are limits to how small transistors can be made before they start to experience  quantum effects, which can cause errors in computation.

### Future of Integrated Circuits

-   To continue improving the performance of electronic devices, researchers are exploring new materials, such as graphene and carbon nanotubes, and new architectures, such as  quantum computing.

## 18. Operating Systems

### Overview

-   An operating system (OS) is a software system that manages computer hardware and software resources and provides common services for computer programs.
-   Some examples of popular operating systems include Windows, macOS, and Linux.

### Functions of an Operating System

-   The main functions of an operating system include managing  computer hardware resources, such as the CPU, memory, and input/output devices, scheduling tasks and processes, providing a user interface, and managing files and directories.

### Kernel

-   The kernel is the core component of an operating system that provides low-level services, such as  memory management,  process scheduling, and  device driver management.
-   The kernel communicates with higher-level components of the operating system, such as the shell and the GUI, to provide a cohesive user experience.

### Types of Operating Systems

-   There are several types of operating systems, including single-user, multi-user, real-time, and embedded systems.
-   Each type has its own unique characteristics and is designed to meet different needs.

### Virtualization

-   Virtualization is a technique that allows multiple operating systems to run on a single physical computer.
-   Virtualization is used to improve resource utilization, isolate applications, and provide better security and availability of services.


### Cloud Computing

-   Cloud computing  is a popular model for delivering  computing resources  over the internet.
-   Cloud computing relies on virtualization and provides on-demand access to computing resources, such as servers, storage, and applications.

## Memory & Storage: Crash Course Computer Science #19

-   Memory  and storage are both important components of a computer system.
-   Memory is used for short-term storage of data and instructions that the CPU needs to access quickly.
-   Storage is used for long-term storage of data that needs to be saved for future use.
-   Memory is typically volatile, meaning that it loses its contents when power is turned off, while storage is typically non-volatile and retains its contents even when power is off.
-   RAM (Random Access Memory) is the most common type of memory used in computers, and it allows the CPU to access data quickly.
-   ROM (Read-Only Memory) is a type of memory that is used to store firmware and other essential software that is required for the computer to function properly.

## Files & File Systems:  Crash Course Computer  Science #20

-   Files and file systems are used to organize and store data on a computer.
-   A file is a collection of data that is stored on a storage device, such as a hard disk or solid-state drive.
-   A  file system  is a software component that manages files and directories on a storage device.
-   File systems use a  hierarchical directory structure  to organize files and directories.
-   Common file systems include FAT, NTFS, and ext4.
-   File systems also provide features such as file permissions, compression, and encryption.

## Compression:  Crash  Course Computer Science #21

-   Compression is the process of reducing the size of data to save storage space and improve transmission speed.
-   Lossless compression algorithms preserve all of the original data when compressing it.
-   Lossy compression algorithms discard some of the original data when compressing it, which can reduce the quality of the compressed data.
-   Common  compression algorithms include  ZIP,  GZIP, and  BZIP2  for  lossless compression, and  JPEG  and  MPEG  for  lossy compression.
-   Compression can be used to reduce the size of files, such as images and videos, and to improve the performance of network transmissions.
